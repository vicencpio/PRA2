---
title: 'Tipologia i cicle de vida de les dades: PRA2'
author: "Autor: Vicenç Pio i Begoña Felip"
date: "Maig 2021"
output:
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: PRA2-header.html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
```

*****
# Tipologia i cicle de vida de les dades
*****
****
# Exercici 1:
****
****
## Descripció del dataset. Perquè és important i quina pregunta/problema pretén respondre?
****

Font de les dades: Titanic: Machine Learning from Disaster (https://www.kaggle.com/c/titanic )

L’enfonsament del RMS Titanic és un dels naufragis més tràgics de la història. El 15 d'abril de 1912, durant el seu viatge inaugural, el Titanic es va enfonsar després de xocar amb un iceberg i va matar 1502 de 2224 passatgers i tripulants. Aquesta catàstrofe va impactar la comunitat internacional i va conduir a una millor normativa de seguretat per als vaixells.
Un dels motius pels quals el naufragi va provocar tanta pèrdua de vides va ser que no hi havia prou vaixells salvavides per als passatgers i la tripulació. Tot i que hi va haver algun element de sort per sobreviure a l’enfonsament, alguns grups de persones tenien més probabilitats de sobreviure que d’altres, com ara dones, nens i la classe alta. 
La pregunta seria analitzar quin tipus de passatgers tenien més probabilitat de sobreviure. S’aplicaran les eines d’aprenentatge automàtic per predir quins passatgers sobreviurien a la tragèdia.

Disponsem de dos grups de dades:

Conjunt d'entrenament (train.csv). Aquest conjunt és el que s'utilitza per a construir el model d'aprenentatge automàtic.

Conjunt de proves (test.csv). Aquest conjunt s'utilitzarà per veure el rendiment del model en dades les quals no disponsem. Per a cada passatger del conjunt de proves, s'utilitza el model que prèviament s'ha entrenat per predir si el passatger va sobreviure o no a l’enfonsament del Titanic.

****
# Exercici 2:
****
****
## Integració i selecció de les dades d’interès a analitzar.
****

```{r echo=TRUE, message=FALSE, warning=FALSE}
trainData <- read.csv('data/train.csv',stringsAsFactors = FALSE)
str(trainData)
```
Tenim 891 observacions i 12 variables.

```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(trainData)
```
Resum de les variables:

**PassengerId** (int): identificador del passatger

**Survived** (int): indica si el passatger va sobreviure (1) o no (0)

**Pclass** (int): classe en què viatjava el passatger (1, 2, 3)

**Name** (chr): nom

**Sex** (chr): male o female

**Age** (int): edat en anys

**SibSp** (int): número de fills i esposes a bord

**Parch** (int): número de pares i mares

**Ticket** (chr): número de ticket

**Fare** (int): preu del ticket

**Cabin** (chr): número de cabina

**Embarked** (chr): lloc d'embarcament (C, Q, S)

Notes sobre les dades

edat: l’edat és fraccionada si és inferior a 1. Si s’estima l’edat, és en forma de xx.5

sibsp: El conjunt de dades defineix les relacions familiars d'aquesta manera ...
Germà = germà, germana, germanastre, germanastra
Cònjuge = marit, dona (les amants i els promès van ser ignorats)

parch: el conjunt de dades defineix les relacions familiars d'aquesta manera ...
Parent = mare, pare
Nen = filla, fill, fillastra, fillastre
Alguns nens només viatjaven amb una mainadera, per tant, parch = 0 per a ells.

****
# Exercici 3:
****
****
## Neteja de les dades. Les dades contenen zeros o elements buits? Com gestionaries aquests casos? 
****

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Registres amb valor NA
colSums(is.na(trainData))
# Registres amb valor buit
colSums(trainData=="")
```

### Assignem valor "Desconeguda" per als valors buits de la variable "Cabin"

```{r echo=TRUE, message=FALSE, warning=FALSE}
trainData$Cabin[trainData$Cabin==""] <- "Desconeguda"
head(trainData$Cabin,10)
```
### Assignem la mitjana per a valors buits de la variable "Age"

```{r echo=TRUE, message=FALSE, warning=FALSE}
trainData$Age[is.na(trainData$Age)] <- signif(mean(trainData$Age,na.rm=T), digits=2)
head(trainData$Age,10)
```
### Assignem NA als valors buits de Embarked:

```{r echo=TRUE, message=FALSE, warning=FALSE}
trainData$Embarked[trainData$Embarked==""] <- NA
head(trainData$Embarked,20)
tail(trainData$Embarked,20)
```

### Identificació i tractament de valors extrems:

```{r echo=TRUE, message=FALSE, warning=FALSE}
Age.bp<-boxplot(trainData$Age,main="Edat")
#En la variable Edat es representen 8 outliers (66.0 71.0 70.5 71.0 80.0 70.0 70.0 74.0). Aquest valors només volen dir que se surten de la mitjana d'edat dels passatgers i no els consideraríem valors anormals.
head(Age.bp$out,8)
Fare.bp<-boxplot(trainData$Fare,main="Tarifa")
#En la variable Fare en surten alguns més, però n'hi ha un en concret molt lluny de la resta.
head(Fare.bp$out,10)
outlier_max<-max(Fare.bp$out,10)
outlier_max
SibSp.bp<-boxplot(trainData$SibSp,main="Nombre de fills i esposes a bord")
#En aquesta variable hi ha 4 outliers,que no vol dir res més que se surten de la mitjana dels valors de la variables SisSp.
head(SibSp.bp$out,8)
```
En aquest cas, no caldria tractar els valors extrems ja que no distorsionen els resultats de les prediccions que volem fer amb la base de dades. Tot i ser valors que surten de la mitjana, no són incorrectes ni errades.
L'outlier amb valor màxim de la variable Fare és `r outlier_max`.

### Discretització variable edat en intervals:

Creem una nova variable discretitzada "segment_edat" que utilitzarem més endavant en anàlisis posteriors.

```{r echo=TRUE, message=FALSE, warning=FALSE}
trainData["segment_edat"] <- cut(trainData$Age, breaks = c(0,10,20,30,40,50,60,70,100), labels = c("0-9", "10-19", "20-29", "30-39","40-49","50-59","60-69","70-79"))
```

### Gràfic:

```{r echo=TRUE, message=FALSE, warning=FALSE}
plot(trainData$segment_edat, col="green")
```

****
# Exercici 4:
****
****
## Mètode d'agregació:
****
En aquest apartat farem un anàlisi de les dades utilitzant un mètode d'agregació. Obtindrem grups (clusters) que agrupen les dades segons la semblança entre elles. Primer de tot importem la llibreria:

```{r message= FALSE, warning=FALSE}
#Llibreria cluster per fer agrupacions
library(cluster)
```

La funció daisy() que utilitzarem per calcular la silueta de la mostra només funciona amb valors numèrics i l'atribut Sex és un string. Per solucionar aquest inconvenient farem un one-hot encoding transformant el Sex en dos nous atributs binaris:

```{r message= FALSE, warning=FALSE}
library(caret)
dummies <- predict(dummyVars(~ Sex, data = trainData), newdata = trainData)
trainData <- cbind(trainData, dummies)
summary(trainData)
```

Els camps que utilitzarem per fer les agrupacions són: Survived, Pclass, Sexmale, Sexfemale i segment_edat:

```{r message= FALSE, warning=FALSE}
train_data <- trainData[ , c("Survived", "Pclass", "Sexfemale", "Sexmale", "Age")]
str(train_data)
```

Passem a executar l'algorisme kmeans, com que inicialment no coneixem el nombre de clusters, provem d'aplicar l'algorisme amb 2, 3, 4, 5, 6, 7 i 8 clústers.

```{r message= FALSE, warning=FALSE}
train_data2       <- kmeans(train_data, 2)
passatgers_cluster2 <- train_data2$cluster

train_data3       <- kmeans(train_data, 3)
passatgers_cluster3 <- train_data3$cluster

train_data4       <- kmeans(train_data, 4)
passatgers_cluster4 <- train_data4$cluster

train_data5       <- kmeans(train_data, 5)
passatgers_cluster5 <- train_data5$cluster

train_data6       <- kmeans(train_data, 6)
passatgers_cluster6 <- train_data6$cluster

train_data7       <- kmeans(train_data, 7)
passatgers_cluster7 <- train_data7$cluster

train_data8       <- kmeans(train_data, 8)
passatgers_cluster8 <- train_data8$cluster
```

Podem veure gràficament els clusters obtinguts amb la següent funció:

```{r message= FALSE, warning=FALSE}

library(plotfunctions)
par(mfrow=c(1,2))

clusplot(train_data, train_data2$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
clusplot(train_data, train_data3$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
clusplot(train_data, train_data4$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
clusplot(train_data, train_data5$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
clusplot(train_data, train_data6$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
clusplot(train_data, train_data7$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
clusplot(train_data, train_data8$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
```

Ara calcularem la silueta de les mostres per avaluar la qualitat del mètode d'agregació.

```{r message= FALSE, warning=FALSE}
set.seed(891)
d <- daisy(train_data)
resultados <- rep(0, 10)
for (i in c(2,3,4,5,6,7,8,9,10))
{
  fit           <- kmeans(train_data, i)
  y_cluster     <- fit$cluster
  sk            <- silhouette(y_cluster, d)
  resultados[i] <- mean(sk[,3])
}
```

Mostrem en un gràfica els valors de les siluetes mitjana de cada prova per a comprovar quin nombre de clústers és el millor.

```{r message= FALSE, warning=FALSE}
plot(2:10,resultados[2:10],type="o",col="blue",pch=0,xlab="Nombre de clústers",ylab="Silueta")
```

Veiem que la millor agrupació és amb 4 clusters i la segona millor amb 3.

Per comparar resultats, provem de fer l'avaluació del millor nombre de clusters amb la funció withinss.

```{r message= FALSE, warning=FALSE}
resultados <- rep(0, 10)
for (i in c(2,3,4,5,6,7,8,9,10))
{
  fit           <- kmeans(train_data, i)
  resultados[i] <- fit$tot.withinss
}
plot(2:10,resultados[2:10],type="o",col="blue",pch=0,xlab="Nombre de clústers",ylab="tot.tot.withinss")
```

En aquesta funció hem de buscar el "colze" de la corba per tenir el millor valor de k. En aquest cas és difícil trobar el millor valor perquè el gràfic té una corba molt rodona i no hi ha cap colze clar, tot i que potser seria el 3 o el 4.

Per últim provarem de fer l'avaluació amb la funció kmeansruns utilitzant els criteris de silueta mitjana i de Calinski-Harabasz:

```{r message= FALSE, warning=FALSE}
library(fpc)
fit_ch  <- kmeansruns(train_data, krange = 1:10, criterion = "ch") 
fit_asw <- kmeansruns(train_data, krange = 1:10, criterion = "asw") 

plot(1:10,fit_ch$crit,type="o",col="blue",pch=0,xlab="Nombre de clústers",ylab="Criteri Calinski-Harabasz")
plot(1:10,fit_asw$crit,type="o",col="blue",pch=0,xlab="Nombre de clústers",ylab="Criteri silueta mitjana")

```
En aquest cas el punt més alt és per k=5 i el segon és k=4, que és el que escollirem perquè ja ens havia sortit abans.

```{r message= FALSE, warning=FALSE}
par(mfrow=c(1,2))

clusplot(train_data, train_data4$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
```

Podem observar que els 4 clusters que s'han format es van solapant l'un amb l'altre, amb el cluster 4 una mica més separat a la part alta.

****
### Arbres de decisió
****

En aquest apartat crearem un conjunt de regles que ens determinaran la probabilitat de sobreviure dels passatgers. Utilitzarem el dataset de train per construir el model i el de test per validar-lo.

Per la visualització gràfica de les variables utilitzarem els paquets ggplot2, gridExtra i grid de R. 

```{r message= FALSE, warning=FALSE}
if(!require(ggplot2)){
    install.packages('ggplot2', repos='http://cran.us.r-project.org')
    library(ggplot2)
}
if(!require(ggpubr)){
    install.packages('ggpubr', repos='http://cran.us.r-project.org')
    library(ggpubr)
}
if(!require(grid)){
    install.packages('grid', repos='http://cran.us.r-project.org')
    library(grid)
}
if(!require(gridExtra)){
    install.packages('gridExtra', repos='http://cran.us.r-project.org')
    library(gridExtra)
}
if(!require(C50)){
    install.packages('C50', repos='http://cran.us.r-project.org')
    library(C50)
}

```

A continuació construim l'arbre de decisió a partir del dataset d'entrenament. A la funció li passem com a primer paràmetre el subconjunt d'entrenament excloent el camp 'Survived' (train_data[-1]) i com a segon paràmetre el propi camp (train_data$Survived):

```{r message= FALSE, warning=FALSE}
set.seed(891)
train_data$Survived = as.factor(train_data$Survived)
model <- C50::C5.0(train_data[-1], train_data$Survived)
summary(model)
```
Veiem que tenim 169 errors (un 19%), que indiquen el nombre de casos mal classificats.

La visualització de l'arbre obtingut és la següent:

```{r message= FALSE, warning=FALSE}
plot(model)
```
En el gràfic podem veure esquemàticament els percentatges de supervivència en funció de les diferents variables.
Ara descomposarem l'arbre en un set de regles amb el flag rules=TRUE:

```{r message= FALSE, warning=FALSE}
model2 <- C50::C5.0(train_data[-1], train_data$Survived, rules = TRUE)
summary(model2)
```

Explicació de les regles:

* Regla 1: Pclass > 2,	Age > 38 → Survived = 0. Validesa: 90,6%
* Regla 2: Sexfemale = 0	→  Survived 0. Validesa: 81,0%
* Regla 3: Pclass <= 2,	Sexfemale = 0,	Age <= 9 →  Survived 1. Validesa: 92,3%
* Regla 4: Sexfemale > 0 →  Survived 1. Validesa: 74,1%

En general podem concloure que els passatgers de classe 1 i 2 i les dones en concret tenen moltes probabilitats de sobreviure, així com els nens menors de 9 anys.

A continuació carreguem les dades de test i les utilitzarem per avaluar quants supervivents hi hauria fent servir el model creat.

```{r message= FALSE, warning=FALSE}
testData <- read.csv('data/test.csv',stringsAsFactors = FALSE)
dummies <- predict(dummyVars(~ Sex, data = testData), newdata = testData)
testData <- cbind(testData, dummies)
dim(testData)
```
Veiem que les dades de test tenen 418 observacions i 13 variables, una menys que les d'entrenament ja que no hi ha el camp Survived, que l'intentarem predir ara:

```{r message= FALSE, warning=FALSE}
predicted_model <- predict( model, testData, type="class" )
summary(predicted_model)
```
Segons la predicció del model, 266 passatgers no sobreviuen i 152 sí.

****
### Model de regressió:
****
Ara passem a avaluar la qualitat del primer model amb esbrinar si la regressió és lineal múltiple (amb regressors quantitatius i qualitatius).

```{r message= FALSE, warning=FALSE}

# Es carrega el conjunt de dades test_data per generar i esbrinar la qualitat del model amb la fòrmula de l'ajustament de regressió lineal lm().

testData <- read.csv('data/test_data.csv',stringsAsFactors = FALSE)
test_data <- testData[ , c("Survived", "Pclass_1", "Pclass_2","Pclass_3","Sex", "Age")]

# Considerem com a variable dependent, la variable Survived, la resta (Age, Sex, i Pclass) les considerarem independents:

model <- lm(Survived ~ Sex + Age + Pclass_1 + Pclass_2 + Pclass_3, test_data ) #Generació i valoració del model.
summary(model)
```

Avaluació de la bondat de l’ajust, a partir del coeficient de determinació o R^2 (R^2 indica el grau d’ajust de la recta de regressió als valors de la mostra): a partir dels resultats anteriors amb la funció summary(), podem veure que el seu valor és Multiple R-squared: 0.3836. Amb aquest valor tant lluny de 1 no podem dir que hi ha regressió lineal entre les variables.

El model amb totes les variables introduïdes com a predictors té un R^2 (Multiple R-squared) 0.3836, el qual és capaç d'explicar el 38.36% de la variabilitat observada en la variable dependent "Survived". Com que no és molt proper al 100%, en principi no és un bon model. El p-value del model és significatiu (2.007e-09) perquè està molt per sota del 0.05 que és el valor d'alfa. Els asterics volen dir que tant la variable Sex, com Pclass_1 són significatives per al resultat del model. Obviament també ho és la variable dependent Survived.

```{r message= FALSE, warning=FALSE}

# Representació gràfica del model:

ggplot(model,aes(model$fitted.values,model$residuals)) + geom_point() + geom_smooth(color = "firebrick", se = FALSE) + geom_hline(yintercept = 0) + theme_bw()

```

# Interpretació del resultat del gràfic:

El gràfic de dispersió serveix per validar la relació lineal entre la variable resposta ("Survived") i els predictors numèrics i categòrics (Age, Sex i Pclass). El gràfic mostra la dispersió entre cada un dels predictors i els residus del model. Com <b> la relació no és lineal </>, els residus gairebé no es distribuexen al voltant de 0 amb una variabilitat més o menys constant al llarg de l'eix X. A més, el gràfic ens permet identificar dades atípiques per les corbes.

```{r message= FALSE, warning=FALSE}
confint(model) # Mostra de l'interval de confiança per cadascun dels coeficients parcials de regressió.
```
### Comprovació de la normalitat i homogeneïtat de la variància (homoscedasticitat).

```{r message= FALSE, warning=FALSE}

# Tenint en compte que la normalització redueix el biaix causat per la combinació de valors mesurats a diferents escales a l’hora d’ajustar-los a una escala comuna, típicament entre (-1,1) o entre (0,1), podríem dir que la nostra base de dades està normalitzada. 

shapiro.test(testData$Survived) # Test de normalitat. El p-valor (5.921e-15) resultant de la prova és més petit que el nivell de significació (0.05), això vol dir que s'observen diferències estadísticament significatives entre el grup de dades testData per a la variable Survived.

# Ara comprovarem l'homoscedasticitat amb el test de variança. Entre les proves més habituals hi ha el test de fligner.test, que s’aplica quan les dades segueixen una distribució normal, com la nostra.

library(car)

fligner.test(Survived ~ Age, data=testData) # Test d'homogeneitat de les variables Survived i Age.

# Com que la prova té un p-valor (0.9796) molt superior al nivell de significació (0,05), no es rebutja la hipòtesi nul·la d’homoscedasticitat i es conclou que la variable Age presenta variàncies estadísticament iguals o similars per als grups de Survived.


fligner.test(Survived ~ Fare, data=testData) # Test d'homogeneitat de les variables Surviveda i Fare.

# Com que la prova té un p-valor (0.6318) molt superior al nivell de significació (0,05), no es rebutja la hipòtesi nul·la d’homoscedasticitat i es conclou que la variable Fare presenta variàncies estadísticament iguals o similars per als grups de Survived.

```

```{r message= FALSE, warning=FALSE}
### Aplicació de proves estadístiques per comparar els grups de dades. En funció de les dades i de l’objectiu de l’estudi, aplicar proves de contrast d’hipòtesis, correlacions, regressions, etc. Aplicar almenys tres mètodes d’anàlisi diferents.

```

*****
# Exercici 5:
*****

Ja hem anat posant gràfics i taules abans, crec que no cal aquest apartat.

*****
# Exercici 6:
*****

* Clustering no permet treure concluions gaire clares.
* Arbres de decisions amb regles sí que ens permeten predir els supervivents per a un dataset de proves.
* Model de regressió...

## Contribucions a la pràctica:

```{r echo=TRUE, message=FALSE, warning=FALSE}

tab <- matrix(c('Vicenç i Begoña', 'Vicenç i Begoña', 'Vicenç i Begoña'), ncol=1, byrow=TRUE)
colnames(tab) <- c('Firma')
rownames(tab) <- c('Investigació prèvia','Redacció de les respostes','Desenvolupament codi')
tab <- as.table(tab)
tab
```