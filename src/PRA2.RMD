---
title: 'Tipologia i cicle de vida de les dades: PRA2'
author: "Autor: Vicenç Pio i Begoña Felip"
date: "Maig 2021"
output:
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: PRA2-header.html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
```

*****
# Tipologia i cicle de vida de les dades
*****
****
# Exercici 1:
****
****
## Descripció del dataset. Perquè és important i quina pregunta/problema pretén respondre?
****

Font de les dades: Titanic: Machine Learning from Disaster (https://www.kaggle.com/c/titanic )

L’enfonsament del RMS Titanic és un dels naufragis més tràgics de la història. El 15 d'abril de 1912, durant el seu viatge inaugural, el Titanic es va enfonsar després de xocar amb un iceberg i va matar 1502 de 2224 passatgers i tripulants. Aquesta catàstrofe va impactar la comunitat internacional i va conduir a una millor normativa de seguretat per als vaixells.
Un dels motius pels quals el naufragi va provocar tanta pèrdua de vides va ser que no hi havia prou vaixells salvavides per als passatgers i la tripulació. Tot i que hi va haver algun element de sort per sobreviure a l’enfonsament, alguns grups de persones tenien més probabilitats de sobreviure que d’altres, com ara dones, nens i la classe alta. 
La pregunta seria analitzar quin tipus de passatgers tenien més probabilitat de sobreviure. S’aplicaran les eines d’aprenentatge automàtic per predir quins passatgers sobreviurien a la tragèdia.

Disponsem de dos grups de dades:

Conjunt d'entrenament (train.csv). Aquest conjunt és el que s'utilitza per a construir el model d'aprenentatge automàtic.

Conjunt de proves (test.csv). Aquest conjunt s'utilitzarà per veure el rendiment del model en dades les quals no disponsem. Per a cada passatger del conjunt de proves, s'utilitza el model que prèviament s'ha entrenat per predir si el passatger va sobreviure o no a l’enfonsament del Titanic.

Aquests dos conjunts de dades estan creats aleatòriament a partir de les dades oficials de passatgers del Titanic.

****
# Exercici 2:
****
****
## Integració i selecció de les dades d’interès a analitzar.
****

```{r echo=TRUE, message=FALSE, warning=FALSE}
trainData <- read.csv('../data/train.csv',stringsAsFactors = FALSE)
str(trainData)
```
Tenim 891 observacions i 12 variables.

```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(trainData)
```
Resum de les variables:

**PassengerId** (int): identificador del passatger

**Survived** (int): indica si el passatger va sobreviure (1) o no (0)

**Pclass** (int): classe en què viatjava el passatger (1, 2, 3)

**Name** (chr): nom

**Sex** (chr): male o female

**Age** (int): edat en anys

**SibSp** (int): número de fills i esposes a bord

**Parch** (int): número de pares i mares

**Ticket** (chr): número de ticket

**Fare** (int): preu del ticket

**Cabin** (chr): número de cabina

**Embarked** (chr): lloc d'embarcament (C, Q, S)

Notes sobre les dades

edat: l’edat és fraccionada si és inferior a 1. Si s’estima l’edat, és en forma de xx.5

sibsp: El conjunt de dades defineix les relacions familiars d'aquesta manera ...
Germà = germà, germana, germanastre, germanastra
Cònjuge = marit, dona (les amants i els promès van ser ignorats)

parch: el conjunt de dades defineix les relacions familiars d'aquesta manera ...
Parent = mare, pare
Nen = filla, fill, fillastra, fillastre
Alguns nens només viatjaven amb una mainadera, per tant, parch = 0 per a ells.

****
# Exercici 3:
****
****
## Neteja de les dades. Les dades contenen zeros o elements buits? Com gestionaries aquests casos? 
****
Comprovem el nombre d'elements buits del joc de dades:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Registres amb valor NA
colSums(is.na(trainData))
# Registres amb valor buit
colSums(trainData=="")
```
Veiem que els camps edat, cabina i embarcat contenen valors buits. Aquesta inexactitud de les dades és degut probablement a que el registre de passatgers no va ser del tot rigurós en aquell moment. Alguns dels passatgers es van colar a bord sense tenir el bitllet, això fa que no es tinguessin dades de l'edat ni de la cabina que tenien.

### Assignem valor "Desconeguda" per als valors buits de la variable "Cabin":

Enlloc de un string en blanc, assignem la paraula "Desconeguda"

```{r echo=TRUE, message=FALSE, warning=FALSE}
trainData$Cabin[trainData$Cabin==""] <- "Desconeguda"
head(trainData$Cabin,10)
```
### Assignem la mitjana per a valors buits de la variable "Age":

En el cas de l'edat assignem la mitjana per no alterar les dades.

```{r echo=TRUE, message=FALSE, warning=FALSE}
trainData$Age[is.na(trainData$Age)] <- signif(mean(trainData$Age,na.rm=T), digits=2)
head(trainData$Age,10)
```
### Assignem NA als valors buits de Embarked:

I pel cas dels camps buits d'Embarked, assignem NA.

```{r echo=TRUE, message=FALSE, warning=FALSE}
trainData$Embarked[trainData$Embarked==""] <- NA
head(trainData$Embarked,20)
tail(trainData$Embarked,20)
```
### Identificació i tractament de valors extrems:

```{r echo=TRUE, message=FALSE, warning=FALSE}
Age.bp<-boxplot(trainData$Age,main="Edat")
#En la variable Edat es representen 8 outliers (66.0 71.0 70.5 71.0 80.0 70.0 70.0 74.0). Aquest valors només volen dir que se surten de la mitjana d'edat dels passatgers i no els consideraríem valors anormals.
head(Age.bp$out,8)
Fare.bp<-boxplot(trainData$Fare,main="Tarifa")
#En la variable Fare en surten alguns més, però n'hi ha un en concret molt lluny de la resta.
head(Fare.bp$out,10)
outlier_max<-max(Fare.bp$out,10)
outlier_max
SibSp.bp<-boxplot(trainData$SibSp,main="Nombre de fills i esposes a bord")
#En aquesta variable hi ha 4 outliers,que no vol dir res més que se surten de la mitjana dels valors de la variables SisSp.
head(SibSp.bp$out,8)
```
En aquest cas, no caldria tractar els valors extrems ja que no distorsionen els resultats de les prediccions que volem fer amb la base de dades. Tot i ser valors que surten de la mitjana, no són incorrectes ni errades.
L'outlier amb valor màxim de la variable Fare és `r outlier_max`.

****
# Exercici 4:
****
****
## Mètode d'agregació:
****
En aquest apartat farem un anàlisi de les dades utilitzant un mètode d'agregació. Obtindrem grups (clusters) que agrupen les dades segons la semblança entre elles. Primer de tot importem la llibreria:

```{r message= FALSE, warning=FALSE}
#Llibreria cluster per fer agrupacions
library(cluster)
```

La funció daisy() que utilitzarem per calcular la silueta de la mostra només funciona amb valors numèrics i l'atribut Sex és un string. Per solucionar aquest inconvenient farem un one-hot encoding transformant el Sex en dos nous atributs binaris:

```{r message= FALSE, warning=FALSE}
library(caret)
dummies <- predict(dummyVars(~ Sex, data = trainData), newdata = trainData)
trainData <- cbind(trainData, dummies)
summary(trainData)
```

Els camps que utilitzarem per fer les agrupacions són: Survived, Pclass, Sexmale, Sexfemale i Age:

```{r message= FALSE, warning=FALSE}
train_data <- trainData[ , c("Survived", "Pclass", "Sexfemale", "Sexmale", "Age")]
str(train_data)
```

Passem a executar l'algorisme kmeans, com que inicialment no coneixem el nombre de clusters, provem d'aplicar l'algorisme amb 2, 3, 4, 5, 6, 7 i 8 clústers.

```{r message= FALSE, warning=FALSE}
train_data2       <- kmeans(train_data, 2)
passatgers_cluster2 <- train_data2$cluster

train_data3       <- kmeans(train_data, 3)
passatgers_cluster3 <- train_data3$cluster

train_data4       <- kmeans(train_data, 4)
passatgers_cluster4 <- train_data4$cluster

train_data5       <- kmeans(train_data, 5)
passatgers_cluster5 <- train_data5$cluster

train_data6       <- kmeans(train_data, 6)
passatgers_cluster6 <- train_data6$cluster

train_data7       <- kmeans(train_data, 7)
passatgers_cluster7 <- train_data7$cluster

train_data8       <- kmeans(train_data, 8)
passatgers_cluster8 <- train_data8$cluster
```

Podem veure gràficament els clusters obtinguts amb la següent funció:

```{r message= FALSE, warning=FALSE}

library(plotfunctions)
par(mfrow=c(1,2))

clusplot(train_data, train_data2$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
clusplot(train_data, train_data3$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
clusplot(train_data, train_data4$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
clusplot(train_data, train_data5$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
clusplot(train_data, train_data6$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
clusplot(train_data, train_data7$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
clusplot(train_data, train_data8$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
```

Ara calcularem la silueta de les mostres per avaluar la qualitat del mètode d'agregació.

```{r message= FALSE, warning=FALSE}
set.seed(891)
d <- daisy(train_data)
resultados <- rep(0, 10)
for (i in c(2,3,4,5,6,7,8,9,10))
{
  fit           <- kmeans(train_data, i)
  y_cluster     <- fit$cluster
  sk            <- silhouette(y_cluster, d)
  resultados[i] <- mean(sk[,3])
}
```

Mostrem en un gràfica els valors de les siluetes mitjana de cada prova per a comprovar quin nombre de clústers és el millor.

```{r message= FALSE, warning=FALSE}
plot(2:10,resultados[2:10],type="o",col="blue",pch=0,xlab="Nombre de clústers",ylab="Silueta")
```

Veiem que la millor agrupació és amb 4 clusters i la segona millor amb 3.

Per comparar resultats, provem de fer l'avaluació del millor nombre de clusters amb la funció withinss.

```{r message= FALSE, warning=FALSE}
resultados <- rep(0, 10)
for (i in c(2,3,4,5,6,7,8,9,10))
{
  fit           <- kmeans(train_data, i)
  resultados[i] <- fit$tot.withinss
}
plot(2:10,resultados[2:10],type="o",col="blue",pch=0,xlab="Nombre de clústers",ylab="tot.tot.withinss")
```

En aquesta funció hem de buscar el "colze" de la corba per tenir el millor valor de k. En aquest cas és difícil trobar el millor valor perquè el gràfic té una corba molt rodona i no hi ha cap colze clar, tot i que potser seria el 3 o el 4.

Per últim provarem de fer l'avaluació amb la funció kmeansruns utilitzant els criteris de silueta mitjana i de Calinski-Harabasz:

```{r message= FALSE, warning=FALSE}
library(fpc)
fit_ch  <- kmeansruns(train_data, krange = 1:10, criterion = "ch") 
fit_asw <- kmeansruns(train_data, krange = 1:10, criterion = "asw") 

plot(1:10,fit_ch$crit,type="o",col="blue",pch=0,xlab="Nombre de clústers",ylab="Criteri Calinski-Harabasz")
plot(1:10,fit_asw$crit,type="o",col="blue",pch=0,xlab="Nombre de clústers",ylab="Criteri silueta mitjana")

```
En aquest cas el punt més alt és per k=5 i el segon és k=4, que és el que escollirem perquè ja ens havia sortit abans.

```{r message= FALSE, warning=FALSE}
clusplot(train_data, train_data4$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
```

Podem observar que els 4 clusters que s'han format es van solapant l'un amb l'altre, amb el cluster 4 una mica més separat a la part alta.

****
### Arbres de decisió.
****

En aquest apartat crearem un conjunt de regles que ens determinaran la probabilitat de sobreviure dels passatgers. Utilitzarem el dataset de train per construir el model i el de test per validar-lo.

Per la visualització gràfica de les variables utilitzarem els paquets ggplot2, gridExtra i grid de R. 

```{r message= FALSE, warning=FALSE}
if(!require(ggplot2)){
    install.packages('ggplot2', repos='http://cran.us.r-project.org')
    library(ggplot2)
}
if(!require(ggpubr)){
    install.packages('ggpubr', repos='http://cran.us.r-project.org')
    library(ggpubr)
}
if(!require(grid)){
    install.packages('grid', repos='http://cran.us.r-project.org')
    library(grid)
}
if(!require(gridExtra)){
    install.packages('gridExtra', repos='http://cran.us.r-project.org')
    library(gridExtra)
}
if(!require(C50)){
    install.packages('C50', repos='http://cran.us.r-project.org')
    library(C50)
}

```

A continuació construim l'arbre de decisió a partir del dataset d'entrenament. A la funció li passem com a primer paràmetre el subconjunt d'entrenament excloent el camp 'Survived' (train_data[-1]) i com a segon paràmetre el propi camp (train_data$Survived):

```{r message= FALSE, warning=FALSE}
set.seed(891)
train_data$Survived = as.factor(train_data$Survived)
model <- C50::C5.0(train_data[-1], train_data$Survived)
summary(model)
```
Veiem que tenim 169 errors (un 19%), que indiquen el nombre de casos mal classificats.

La visualització de l'arbre obtingut és la següent:

```{r message= FALSE, warning=FALSE}
plot(model)
```
En el gràfic podem veure esquemàticament els percentatges de supervivència en funció de les diferents variables.
Ara descomposarem l'arbre en un set de regles amb el flag rules=TRUE:

```{r message= FALSE, warning=FALSE}
model2 <- C50::C5.0(train_data[-1], train_data$Survived, rules = TRUE)
summary(model2)
```

Explicació de les regles:

* Regla 1: Pclass > 2,	Age > 38 → Survived = 0. Validesa: 90,6%
* Regla 2: Sexfemale = 0	→  Survived 0. Validesa: 81,0%
* Regla 3: Pclass <= 2,	Sexfemale = 0,	Age <= 9 →  Survived 1. Validesa: 92,3%
* Regla 4: Sexfemale > 0 →  Survived 1. Validesa: 74,1%

En general podem concloure que els passatgers de classe 1 i 2 i les dones en concret tenen moltes probabilitats de sobreviure, així com els nens menors de 9 anys.

A continuació carreguem les dades de test i les utilitzarem per avaluar quants supervivents hi hauria fent servir el model creat.

```{r message= FALSE, warning=FALSE}
testData <- read.csv('../data/test.csv',stringsAsFactors = FALSE)
dummies <- predict(dummyVars(~ Sex, data = testData), newdata = testData)
testData <- cbind(testData, dummies)
dim(testData)
```
Veiem que les dades de test tenen 418 observacions i 13 variables, una menys que les d'entrenament ja que no hi ha el camp Survived, que l'intentarem predir ara:

```{r message= FALSE, warning=FALSE}
predicted_model <- predict( model, testData, type="class" )
summary(predicted_model)
```
Segons la predicció del model, 266 passatgers no sobreviuen i 152 sí.

****
### Model de regressió lineal múltiple (regresors quantitatius i qualitatius)
****
****
## Proves de contrast d’hipòtesis, correlacions, regressions, etc. 
****

Ara passem a avaluar la qualitat del primer model amb esbrinar si la regressió és lineal múltiple (amb regressors quantitatius i qualitatius).
Carregem el conjunt de dades train_data per generar i esbrinar la qualitat del model amb la fòrmula de l'ajustament de regressió lineal lm().

```{r message= FALSE, warning=FALSE}

# Torno als valors de train.csv, perquè considero que per fer el model de regressió la variable dependent més significativa és Survived.

trainData <- read.csv('../data/train.csv',stringsAsFactors = FALSE)
train_data <- trainData[ , c("Survived", "Pclass","Sex", "Age","Fare")]

# Considerem com a variable dependent, la variable Survived, la resta (Age, Sex, Fare i Pclass) les considerarem independents:

model <- lm(Survived ~ Sex + Age + Pclass+Fare, train_data ) #Generació i valoració del model.
summary(model)
```

Avaluació de la bondat de l’ajust, a partir del coeficient de determinació o R^2 (R^2 indica el grau d’ajust de la recta de regressió als valors de la mostra): a partir dels resultats anteriors amb la funció summary(), podem veure que el seu valor és Multiple R-squared: 0.3902. Amb aquest valor tant lluny de 1 no podem dir que hi ha regressió lineal entre les variables.

El model amb totes les variables introduïdes com a predictors té un R^2 (Multiple R-squared) 0.3902, el qual és capaç d'explicar el 39% de la variabilitat observada en la variable dependent "Survived". Com que no és molt proper al 100%, en principi no és un bon model. El p-value del model és significatiu (2.2e-16) perquè està molt per sota del 0.05 que és el valor d'alfa. Els asterics volen dir que tant la variable SexMale (els homes en aquest cas), com Pclass i Age són significatives per al resultat del model. La variable Fare no és significativa per al model.

A partir de la pregunta del principi, característiques dels passatgers que tenien més probabilitats de sobrevisure a l'enfonsament, el que podem deduir és que <b> tant el Sexe, l'Edat i les condicions econòmiques en que es realitzaven el viatge (Classe i Tarifa) són rellevants i significatives per la supervivència</b>.

```{r message= FALSE, warning=FALSE}

# Representació gràfica del model (valors ajustats enfront dels residus que ens permetrà veure si la variància és constant)

ggplot(model,aes(model$fitted.values,model$residuals)) + geom_point() + geom_smooth(color = "firebrick", se = FALSE) + geom_hline(yintercept = 0) + theme_bw()

```

# Interpretació del resultat del gràfic:

El gràfic de dispersió serveix per validar la relació lineal entre la variable resposta ("Survived") i els predictors numèrics i categòrics (Age, Sex, Pclass i Fare). El gràfic mostra la dispersió entre cada un dels predictors i els residus del model. Com <b> la relació no és lineal </>, els residus gairebé no es distribuexen al voltant de 0 amb una variabilitat més o menys constant al llarg de l'eix X. A més, el gràfic ens permet identificar dades atípiques per les corbes.

```{r message= FALSE, warning=FALSE}

### Gràfic per visualitzar la normalitat.

# Gràfic quantil-quantil que compara els residus del model amb els valors d’una variable que es distribueix normalment(QQ plot).

qqnorm(model$residuals)
qqline(model$residuals)

```

A partir del gràfic s’observa un patró de dispersió prou regular fins a l'extrem superior. A trets, sembla un patró aleatori dels residus. Això indica que no es compleix al 100%  el supòsit de variància constant en els errors del model. D’altra banda el Q_Q plot, mostra que les dades no s’ajusten sempre a una normal.

### Comprovació de la normalitat i homogeneïtat de la variància (homoscedasticitat).

## Contrast d'hipòtesis:

Tenint en compte que la normalització redueix el biaix causat per la combinació de valors mesurats a diferents escales a l’hora d’ajustar-los a una escala comuna, típicament entre (-1,1) o entre (0,1), podríem dir que la nostra base de dades està normalitzada. 

Per a realitzar el test partiriem d'una hipòtesis nul·la (variàcies iguals en les mostres) i una hipòtesis alternativa (variàcies iguals en les mostres).

H0 - Hipòtesis nul·la --> var1 = var2
H1 - Hipòtesis alternativa--> var1 <> var2

```{r message= FALSE, warning=FALSE}

shapiro.test(trainData$Survived) # Test de Shapiro.

```
Test de normalitat Shapiro on el p-valor (2.2e-16) resultant de la prova és més petit que el nivell de significació (0.05), això vol dir que s'observen diferències estadísticament significatives entre el grup de dades trainData per a la variable Survived.

Ara comprovarem l'homoscedasticitat amb el test de variança. Entre les proves més habituals hi ha el test de fligner.test, que s’aplica quan les dades segueixen una distribució normal.

```{r message= FALSE, warning=FALSE}
library(car)

fligner.test(Survived ~ Age, data=trainData) # Test d'homogeneitat de les variables Survived i Age.
```
Com que la prova té un p-valor (0.8562) molt superior al nivell de significació (0.05), no es rebutja la hipòtesi nul·la d’homoscedasticitat i es conclou que la variable Age presenta variàncies estadísticament iguals o similars per als grups de Survived.

```{r message= FALSE, warning=FALSE}

fligner.test(Survived ~ Sex, data=trainData) # Test d'homogeneitat de les variables Survived i Sex.
```
Com que la prova té un p-valor (0.01627), inferior al nivell de significació (0.05), es rebutja la hipòtesi nul·la d’homoscedasticitat i es conclou que la variable Sex no presenta variàncies estadísticament similars per als grups de Survived.

```{r message= FALSE, warning=FALSE}

fligner.test(Survived ~ Pclass, data=trainData) # Test d'homogeneitat de les variables Survived i Pclass.
```
Com que la prova té un p-valor (1.712e-08) molt inferior al nivell de significació (0.05), es rebutja la hipòtesi nul·la d’homoscedasticitat.

```{r message= FALSE, warning=FALSE}

fligner.test(Survived ~ Fare, data=trainData) # Test d'homogeneitat de les variables Survived i Fare.
```
Com que la prova té un p-valor (0.299) superior al nivell de significació (0.05), no es rebutja la hipòtesi nul·la d’homoscedasticitat.

## Correlacions:

```{r message= FALSE, warning=FALSE}

corel<- cor(train_data$Survived,train_data$Fare, method = "pearson")
corel2<- cor(train_data$Survived,train_data$Pclass, method = "pearson")

train_data$Age[is.na(train_data$Age)] <- signif(mean(train_data$Age,na.rm=T), digits=2) # Per als valors buits de la variable Age, assignaré la mitjana d'edat.
corel3<-cor(train_data$Survived,train_data$Age, method = "pearson")

```

Anàlisi de la relació entre les variables Survived i Fare. Aquesta informació és crítica a l'hora d'identificar quins poden ser els millors predictors per al model, quines variables presenten relacions de tipus no lineal (motiu pel que no poden ser incloses) i per identificar col·linealitat entre predictors. Fare seria un bon predictor. El valor és `r corel` perquè està entre 0 i 1 en valor positiu, com faig referència en el següent apartat. 

Per poder realitzar comparacions entre variables, s'ha estandarditzar la covariància, generant els coeficients de correlació. He triat Pearson perquè funciona bé amb variables quantitatives que tenen una distribució normal, tot i que tots varien entre +1 (correlació positiva perfecta) i -1 (correlació negativa perfecta).

El coeficient de correlació entre Survived i Age és `r corel3`, i es tracta d'una correlació negativa perfecta.

Per últim el coeficient de correlació entre Survived i PClass és `r corel2`, que també es tracta d'una correlació negativa perfecta.

## Intervals de confiança del model:
```{r message= FALSE, warning=FALSE}

confint(model) 

```

La funció confint mostra  l'interval de confiança per cadascun dels coeficients parcials de regressió. Cadascun dels coeficients parcials de regressió dels predictors són les pendents d'un model de regressió lineal múltiple.


*****
# Exercici 5:
*****

```{r message= FALSE, warning=FALSE}

# Gràfic que mostra la distribució entre Supervivients i no supervivents.

plot(trainData$Survived,  xlab = "Supervivents", ylab = "Frecuencia", col = c("seagreen", "purple"))

#Gràfics que representen les dades estudiades (Survived i Sex)

taula1<-table(trainData$Sex,trainData$Survived)

barplot(taula1,  col = c("lightblue", "mistyrose"), xlab="Supervivents?", ylab= "Nombre de dones i homes", legend=TRUE, main = "Supervivents per sexe", data = trainData)

graf_prop_Sexe <- prop.table(taula1, margin = 1)
barplot(graf_prop_Sexe, col = c( "lavender", "cornsilk"), xlab="Supervivents?", ylab= "Percentatge de dones i homes", legend=TRUE, main = "Percentatge de supervivents per sexe", data = trainData)

#Gràfics que representen les dades estudiades (Survived i Age):

taula2<-table(trainData$Survived,trainData$Age)

barplot(taula2,  col = c("mistyrose", "lightcyan"), xlab="Edat", ylab=" Nombre de supervivents", legend=TRUE, main = "Supervivents per Edat", data = trainData)

graf_prop_Edat <- prop.table(taula2, margin = 1)
barplot(graf_prop_Edat, col = c( "lavender", "blue"), xlab="Edat", ylab= "Percentatge per edat", legend=TRUE, main = "Percentatge de supervivents per edat", data = trainData)

#Gràfics que representen les dades estudiades (Survived i Pclass):

taula3<-table(trainData$Survived,trainData$Pclass)

barplot(taula3,  col = c("blue", "lightcyan"), xlab="Classe", ylab=" Nombre de supervivents", legend=TRUE, main = "Supervivents per Classe", data = trainData)

graf_prop_Classe <- prop.table(taula3, margin = 1)
barplot(graf_prop_Classe, col = c( "grey", "blue"), xlab="Classe", ylab= "Percentatge per Classe", legend=TRUE, main = "Percentatge de supervivents per Classe", data = trainData)
```
*****
# Exercici 6:
*****

* Clustering: és difícil extreure conclusions del model d'agregació creat ja que els clusters obtinguts no mostren una distinció clara entre ells sinó que queden agrupats des de la part baixa del gràfic fins a la part més alta en grups semblants que se solapen entre ells.

* Arbres de decisions amb regles: en aquest cas sí que podem obtenir una predicció dels supervivents utilitzant el model creat. Primer hem generat un arbre de decisió que ens porta a saber la probabilitat de supervivència en base a les variables utilitzades amb un error del 19%. A partir de l'arbre obtenim el joc de regles que també ens indiquen la probabilitat de supervivència amb el percentatge de validesa per cada regla. Per últim calculem la predicció utilitzant el joc de dades de test.

* Model de regressió: amb el model de regressió s'avalua la qualitat del primer model esbrinant si la regressió és lineal múltiple (amb regressors quantitatius i qualitatius) Es realitza amb el conjunt de dades train_data per esbrinar la qualitat del model amb la fòrmula de l'ajustament de regressió lineal lm(). S'avalua la bondat de l’ajust, a partir del coeficient de determinació o R^2. Es conclou amb els valors de l'anàlisis que, en principi, el model no és prou bo. Realitzem també un gràfic per fer una interpretació visual del model de regressió, el qual serveix per validar la relació lineal entre la variable resposta ("Survived") i els predictors numèrics i categòrics (Age, Sex, Pclass i Fare). El gràfic mostra la dispersió entre cada un dels predictors i els residus del model. 

* S'han calculat contrast d'hipòtesis, correlacions i regressions arribant a les següents conclusions: 

Per realitzar el test s'ha partit de l'hipòtesis nul·la (variàcies iguals en les mostres) i l'hipòtesis alternativa (variàcies iguals en les mostres).

Correlacions (només es poden realitzar amb variables numèriques): el millor valor predictor és Fare perquè és un valor positiu que està entre 0 i 1. Age i Pclass són predictors a tenir en compte, però saben que són coeficients de correlació negatius perfectes.

La funció confint mostra  l'interval de confiança per cadascun dels coeficients parcials de regressió. Cadascun dels coeficients parcials de regressió dels predictors són les pendents d'un model de regressió lineal múltiple.

* Comprovació de la normalitat i homogeneïtat de la variància (homoscedasticitat): hem comprovat que la base de dades utilitzada està normalitzada utilitzant el test de normalitat de Shapiro. L'homoscedasticitat l'hem comprovada amb un test de variança anomenat fligner.test que hem considerat el més adequat per ser d'ús habitual quan les dades segueixen una distribució normal. També s'han realitzat dos gràfics de comprovació de la normalitat i la homohomoscedasticitat.

## Contribucions a la pràctica:

```{r echo=TRUE, message=FALSE, warning=FALSE}

tab <- matrix(c('Vicenç i Begoña', 'Vicenç i Begoña', 'Vicenç i Begoña'), ncol=1, byrow=TRUE)
colnames(tab) <- c('Firma')
rownames(tab) <- c('Investigació prèvia','Redacció de les respostes','Desenvolupament codi')
tab <- as.table(tab)
tab
```